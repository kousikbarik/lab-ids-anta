{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55185ab-47ee-40b2-a9f7-84f26a4649ff",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69228d23-50fd-47bb-a2c3-0f82601fc9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5d412-73dc-4e9f-a7f7-3f64818fe3e9",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2662f7c9-5d96-4991-9aa6-4a98cbf75a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>SimillarHTTP</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>192.168.50.254-224.0.0.5-0-0-0</td>\n",
       "      <td>192.168.50.254</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-03 09:18:16.964447</td>\n",
       "      <td>114456999</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>28337.112288</td>\n",
       "      <td>98168.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9529897.25</td>\n",
       "      <td>351582.631269</td>\n",
       "      <td>10001143.0</td>\n",
       "      <td>9048097.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>192.168.50.253-224.0.0.5-0-0-0</td>\n",
       "      <td>192.168.50.253</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-03 09:18:18.506537</td>\n",
       "      <td>114347504</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>121314.911865</td>\n",
       "      <td>420255.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9493929.75</td>\n",
       "      <td>351541.079539</td>\n",
       "      <td>9978130.0</td>\n",
       "      <td>8820294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176563</td>\n",
       "      <td>172.217.10.98-192.168.50.6-443-54799-6</td>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54799</td>\n",
       "      <td>172.217.10.98</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610576</td>\n",
       "      <td>36435473</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62416.0</td>\n",
       "      <td>62416.0</td>\n",
       "      <td>36373056.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50762</td>\n",
       "      <td>172.217.7.2-192.168.50.6-443-54800-6</td>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54800</td>\n",
       "      <td>172.217.7.2</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610579</td>\n",
       "      <td>36434705</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62413.0</td>\n",
       "      <td>62413.0</td>\n",
       "      <td>36372291.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36372291.0</td>\n",
       "      <td>36372291.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87149</td>\n",
       "      <td>172.217.10.98-192.168.50.6-443-54801-6</td>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54801</td>\n",
       "      <td>172.217.10.98</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610581</td>\n",
       "      <td>36434626</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62409.0</td>\n",
       "      <td>62409.0</td>\n",
       "      <td>36372216.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191689</th>\n",
       "      <td>141421</td>\n",
       "      <td>172.16.0.5-192.168.50.4-855-47131-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>855</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>47131</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:48.919833</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191690</th>\n",
       "      <td>189763</td>\n",
       "      <td>172.16.0.5-192.168.50.4-856-53617-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>856</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>53617</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:48.920175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191691</th>\n",
       "      <td>52484</td>\n",
       "      <td>172.16.0.5-192.168.50.4-857-9612-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>857</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>9612</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:48.920464</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191692</th>\n",
       "      <td>176631</td>\n",
       "      <td>172.16.0.5-192.168.50.4-858-23408-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>858</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>23408</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:48.920466</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191693</th>\n",
       "      <td>169688</td>\n",
       "      <td>172.16.0.5-192.168.50.4-859-50418-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>859</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>50418</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:48.920515</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191694 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                 Flow ID       Source IP  \\\n",
       "0               24          192.168.50.254-224.0.0.5-0-0-0  192.168.50.254   \n",
       "1               26          192.168.50.253-224.0.0.5-0-0-0  192.168.50.253   \n",
       "2           176563  172.217.10.98-192.168.50.6-443-54799-6    192.168.50.6   \n",
       "3            50762    172.217.7.2-192.168.50.6-443-54800-6    192.168.50.6   \n",
       "4            87149  172.217.10.98-192.168.50.6-443-54801-6    192.168.50.6   \n",
       "...            ...                                     ...             ...   \n",
       "191689      141421    172.16.0.5-192.168.50.4-855-47131-17      172.16.0.5   \n",
       "191690      189763    172.16.0.5-192.168.50.4-856-53617-17      172.16.0.5   \n",
       "191691       52484     172.16.0.5-192.168.50.4-857-9612-17      172.16.0.5   \n",
       "191692      176631    172.16.0.5-192.168.50.4-858-23408-17      172.16.0.5   \n",
       "191693      169688    172.16.0.5-192.168.50.4-859-50418-17      172.16.0.5   \n",
       "\n",
       "         Source Port  Destination IP   Destination Port   Protocol  \\\n",
       "0                  0       224.0.0.5                  0          0   \n",
       "1                  0       224.0.0.5                  0          0   \n",
       "2              54799   172.217.10.98                443          6   \n",
       "3              54800     172.217.7.2                443          6   \n",
       "4              54801   172.217.10.98                443          6   \n",
       "...              ...             ...                ...        ...   \n",
       "191689           855    192.168.50.4              47131         17   \n",
       "191690           856    192.168.50.4              53617         17   \n",
       "191691           857    192.168.50.4               9612         17   \n",
       "191692           858    192.168.50.4              23408         17   \n",
       "191693           859    192.168.50.4              50418         17   \n",
       "\n",
       "                         Timestamp   Flow Duration   Total Fwd Packets  ...  \\\n",
       "0       2018-11-03 09:18:16.964447       114456999                  45  ...   \n",
       "1       2018-11-03 09:18:18.506537       114347504                  56  ...   \n",
       "2       2018-11-03 09:18:18.610576        36435473                   6  ...   \n",
       "3       2018-11-03 09:18:18.610579        36434705                   6  ...   \n",
       "4       2018-11-03 09:18:18.610581        36434626                   6  ...   \n",
       "...                            ...             ...                 ...  ...   \n",
       "191689  2018-11-03 10:01:48.919833               1                   2  ...   \n",
       "191690  2018-11-03 10:01:48.920175               1                   2  ...   \n",
       "191691  2018-11-03 10:01:48.920464               1                   2  ...   \n",
       "191692  2018-11-03 10:01:48.920466              49                   2  ...   \n",
       "191693  2018-11-03 10:01:48.920515               1                   2  ...   \n",
       "\n",
       "           Active Std   Active Max   Active Min    Idle Mean       Idle Std  \\\n",
       "0        28337.112288      98168.0          3.0   9529897.25  351582.631269   \n",
       "1       121314.911865     420255.0          4.0   9493929.75  351541.079539   \n",
       "2            0.000000      62416.0      62416.0  36373056.00       0.000000   \n",
       "3            0.000000      62413.0      62413.0  36372291.00       0.000000   \n",
       "4            0.000000      62409.0      62409.0  36372216.00       0.000000   \n",
       "...               ...          ...          ...          ...            ...   \n",
       "191689       0.000000          0.0          0.0         0.00       0.000000   \n",
       "191690       0.000000          0.0          0.0         0.00       0.000000   \n",
       "191691       0.000000          0.0          0.0         0.00       0.000000   \n",
       "191692       0.000000          0.0          0.0         0.00       0.000000   \n",
       "191693       0.000000          0.0          0.0         0.00       0.000000   \n",
       "\n",
       "          Idle Max    Idle Min  SimillarHTTP   Inbound    Label  \n",
       "0       10001143.0   9048097.0             0         0   BENIGN  \n",
       "1        9978130.0   8820294.0             0         0   BENIGN  \n",
       "2       36373056.0  36373056.0             0         0   BENIGN  \n",
       "3       36372291.0  36372291.0             0         0   BENIGN  \n",
       "4       36372216.0  36372216.0             0         0   BENIGN  \n",
       "...            ...         ...           ...       ...      ...  \n",
       "191689         0.0         0.0             0         1  Portmap  \n",
       "191690         0.0         0.0             0         1  Portmap  \n",
       "191691         0.0         0.0             0         1  Portmap  \n",
       "191692         0.0         0.0             0         1  Portmap  \n",
       "191693         0.0         0.0             0         1  Portmap  \n",
       "\n",
       "[191694 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(r\"E:\\train\\Portmap.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ddfeed-5a6d-4612-a1b1-8633501788b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         60000\n",
       "Flow ID            59653\n",
       " Source IP           136\n",
       " Source Port        1691\n",
       " Destination IP      191\n",
       "                   ...  \n",
       " Idle Max            231\n",
       " Idle Min            231\n",
       "SimillarHTTP          33\n",
       " Inbound               2\n",
       " Label                 2\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Unique Values\n",
    "df2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a2ad79-5df6-4b7b-a0a5-021092273891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Flow ID            0\n",
       " Source IP         0\n",
       " Source Port       0\n",
       " Destination IP    0\n",
       "                  ..\n",
       " Idle Max          0\n",
       " Idle Min          0\n",
       "SimillarHTTP       0\n",
       " Inbound           0\n",
       " Label             0\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the null values\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eaa8a15-ee93-4d85-a4f3-23de5ee0571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df2 = pd.read_csv(r\"E:\\train\\Portmap.csv\")\n",
    "\n",
    "# Reduce the DataFrame to 60000 randomly selected rows\n",
    "df2_random_sample = df2.sample(n=60000, random_state=42)  # You can choose any random_state value for reproducibility\n",
    "\n",
    "# Define the file path where you want to save the CSV file\n",
    "output_file_path = r\"E:\\train\\sampled_data_2019.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df2_random_sample.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Index=False is used to prevent pandas from writing row indices to the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8063a8-ab57-4455-9b58-2171740ce484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>SimillarHTTP</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138303</td>\n",
       "      <td>172.16.0.5-192.168.50.4-771-21036-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>771</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>21036</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:31.745565</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82138</td>\n",
       "      <td>172.16.0.5-192.168.50.4-648-11467-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>648</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>11467</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:26.675037</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167098</td>\n",
       "      <td>172.16.0.5-192.168.50.4-878-8938-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>878</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>8938</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:43.948928</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51489</td>\n",
       "      <td>172.217.9.226-192.168.50.8-443-59665-6</td>\n",
       "      <td>192.168.50.8</td>\n",
       "      <td>59665</td>\n",
       "      <td>172.217.9.226</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:37:01.880001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55916</td>\n",
       "      <td>172.16.0.5-192.168.50.4-648-59798-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>648</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>59798</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:32.710718</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>77136</td>\n",
       "      <td>172.16.0.5-192.168.50.4-711-47442-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>711</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>47442</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:43.991813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>25247</td>\n",
       "      <td>172.16.0.5-192.168.50.4-856-55663-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>856</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>55663</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:39.200449</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>78077</td>\n",
       "      <td>172.16.0.5-192.168.50.4-535-38375-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>535</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>38375</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:41.426430</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>116600</td>\n",
       "      <td>172.16.0.5-192.168.50.4-881-38905-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>881</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>38905</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:45.834291</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>17552</td>\n",
       "      <td>172.16.0.5-192.168.50.4-1007-35930-17</td>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>1007</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>35930</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-11-03 10:01:34.634240</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Portmap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                 Flow ID     Source IP  \\\n",
       "0          138303    172.16.0.5-192.168.50.4-771-21036-17    172.16.0.5   \n",
       "1           82138    172.16.0.5-192.168.50.4-648-11467-17    172.16.0.5   \n",
       "2          167098     172.16.0.5-192.168.50.4-878-8938-17    172.16.0.5   \n",
       "3           51489  172.217.9.226-192.168.50.8-443-59665-6  192.168.50.8   \n",
       "4           55916    172.16.0.5-192.168.50.4-648-59798-17    172.16.0.5   \n",
       "...           ...                                     ...           ...   \n",
       "59995       77136    172.16.0.5-192.168.50.4-711-47442-17    172.16.0.5   \n",
       "59996       25247    172.16.0.5-192.168.50.4-856-55663-17    172.16.0.5   \n",
       "59997       78077    172.16.0.5-192.168.50.4-535-38375-17    172.16.0.5   \n",
       "59998      116600    172.16.0.5-192.168.50.4-881-38905-17    172.16.0.5   \n",
       "59999       17552   172.16.0.5-192.168.50.4-1007-35930-17    172.16.0.5   \n",
       "\n",
       "        Source Port  Destination IP   Destination Port   Protocol  \\\n",
       "0               771    192.168.50.4              21036         17   \n",
       "1               648    192.168.50.4              11467         17   \n",
       "2               878    192.168.50.4               8938         17   \n",
       "3             59665   172.217.9.226                443          6   \n",
       "4               648    192.168.50.4              59798         17   \n",
       "...             ...             ...                ...        ...   \n",
       "59995           711    192.168.50.4              47442         17   \n",
       "59996           856    192.168.50.4              55663         17   \n",
       "59997           535    192.168.50.4              38375         17   \n",
       "59998           881    192.168.50.4              38905         17   \n",
       "59999          1007    192.168.50.4              35930         17   \n",
       "\n",
       "                        Timestamp   Flow Duration   Total Fwd Packets  ...  \\\n",
       "0      2018-11-03 10:01:31.745565              49                   2  ...   \n",
       "1      2018-11-03 10:01:26.675037               1                   2  ...   \n",
       "2      2018-11-03 10:01:43.948928               1                   2  ...   \n",
       "3      2018-11-03 09:37:01.880001               3                   2  ...   \n",
       "4      2018-11-03 10:01:32.710718               1                   2  ...   \n",
       "...                           ...             ...                 ...  ...   \n",
       "59995  2018-11-03 10:01:43.991813               1                   2  ...   \n",
       "59996  2018-11-03 10:01:39.200449               1                   2  ...   \n",
       "59997  2018-11-03 10:01:41.426430               1                   2  ...   \n",
       "59998  2018-11-03 10:01:45.834291               1                   2  ...   \n",
       "59999  2018-11-03 10:01:34.634240               1                   2  ...   \n",
       "\n",
       "        Active Std   Active Max   Active Min  Idle Mean   Idle Std   Idle Max  \\\n",
       "0              0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "1              0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "2              0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "3              0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "4              0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "...            ...          ...          ...        ...        ...        ...   \n",
       "59995          0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "59996          0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "59997          0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "59998          0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "59999          0.0          0.0          0.0        0.0        0.0        0.0   \n",
       "\n",
       "        Idle Min  SimillarHTTP   Inbound    Label  \n",
       "0            0.0             0         1  Portmap  \n",
       "1            0.0             0         1  Portmap  \n",
       "2            0.0             0         1  Portmap  \n",
       "3            0.0             0         0   BENIGN  \n",
       "4            0.0             0         1  Portmap  \n",
       "...          ...           ...       ...      ...  \n",
       "59995        0.0             0         1  Portmap  \n",
       "59996        0.0             0         1  Portmap  \n",
       "59997        0.0             0         1  Portmap  \n",
       "59998        0.0             0         1  Portmap  \n",
       "59999        0.0             0         1  Portmap  \n",
       "\n",
       "[60000 rows x 88 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(r\"E:\\train\\sampled_data_2019.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3abab7c-7bf1-4c38-be39-d5d42947336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for each class:\n",
      " Label\n",
      "Portmap    58533\n",
      "BENIGN      1467\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df2 = pd.read_csv(r\"E:\\train\\sampled_data_2019.csv\")\n",
    "\n",
    "# Get the value counts for the 'Label' column\n",
    "label_counts = df2[' Label'].value_counts()\n",
    "\n",
    "# Print the value counts\n",
    "print(\"Value counts for each class:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4aa9e5-788e-4078-acc1-31f082294b91",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44bd3956-a36e-43e2-a4e3-e4904a8d51a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Unnamed: 0                                 Flow ID     Source IP  \\\n",
      "0      138303    172.16.0.5-192.168.50.4-771-21036-17    172.16.0.5   \n",
      "1       82138    172.16.0.5-192.168.50.4-648-11467-17    172.16.0.5   \n",
      "2      167098     172.16.0.5-192.168.50.4-878-8938-17    172.16.0.5   \n",
      "3       51489  172.217.9.226-192.168.50.8-443-59665-6  192.168.50.8   \n",
      "4       55916    172.16.0.5-192.168.50.4-648-59798-17    172.16.0.5   \n",
      "\n",
      "    Source Port  Destination IP   Destination Port   Protocol  \\\n",
      "0           771    192.168.50.4              21036         17   \n",
      "1           648    192.168.50.4              11467         17   \n",
      "2           878    192.168.50.4               8938         17   \n",
      "3         59665   172.217.9.226                443          6   \n",
      "4           648    192.168.50.4              59798         17   \n",
      "\n",
      "                    Timestamp   Flow Duration   Total Fwd Packets  ...  \\\n",
      "0  2018-11-03 10:01:31.745565              49                   2  ...   \n",
      "1  2018-11-03 10:01:26.675037               1                   2  ...   \n",
      "2  2018-11-03 10:01:43.948928               1                   2  ...   \n",
      "3  2018-11-03 09:37:01.880001               3                   2  ...   \n",
      "4  2018-11-03 10:01:32.710718               1                   2  ...   \n",
      "\n",
      "    Active Std   Active Max   Active Min  Idle Mean   Idle Std   Idle Max  \\\n",
      "0          0.0          0.0          0.0        0.0        0.0        0.0   \n",
      "1          0.0          0.0          0.0        0.0        0.0        0.0   \n",
      "2          0.0          0.0          0.0        0.0        0.0        0.0   \n",
      "3          0.0          0.0          0.0        0.0        0.0        0.0   \n",
      "4          0.0          0.0          0.0        0.0        0.0        0.0   \n",
      "\n",
      "    Idle Min  SimillarHTTP   Inbound    Label  \n",
      "0        0.0             0         1  Portmap  \n",
      "1        0.0             0         1  Portmap  \n",
      "2        0.0             0         1  Portmap  \n",
      "3        0.0             0         0   BENIGN  \n",
      "4        0.0             0         1  Portmap  \n",
      "\n",
      "[5 rows x 88 columns]\n",
      "\n",
      "Normalized Data:\n",
      "   Unnamed: 0                                 Flow ID     Source IP  \\\n",
      "0    0.764925    172.16.0.5-192.168.50.4-771-21036-17    172.16.0.5   \n",
      "1   -0.252852    172.16.0.5-192.168.50.4-648-11467-17    172.16.0.5   \n",
      "2    1.286725     172.16.0.5-192.168.50.4-878-8938-17    172.16.0.5   \n",
      "3   -0.808248  172.217.9.226-192.168.50.8-443-59665-6  192.168.50.8   \n",
      "4   -0.728026    172.16.0.5-192.168.50.4-648-59798-17    172.16.0.5   \n",
      "\n",
      "    Source Port  Destination IP   Destination Port   Protocol  \\\n",
      "0     -0.155523    192.168.50.4          -0.574434   0.136678   \n",
      "1     -0.169770    192.168.50.4          -1.069760   0.136678   \n",
      "2     -0.143130    192.168.50.4          -1.200670   0.136678   \n",
      "3      6.665869   172.217.9.226          -1.640402  -7.182904   \n",
      "4     -0.169770    192.168.50.4           1.432027   0.136678   \n",
      "\n",
      "                    Timestamp   Flow Duration   Total Fwd Packets  ...  \\\n",
      "0  2018-11-03 10:01:31.745565       -0.059227           -0.048101  ...   \n",
      "1  2018-11-03 10:01:26.675037       -0.059235           -0.048101  ...   \n",
      "2  2018-11-03 10:01:43.948928       -0.059235           -0.048101  ...   \n",
      "3  2018-11-03 09:37:01.880001       -0.059235           -0.048101  ...   \n",
      "4  2018-11-03 10:01:32.710718       -0.059235           -0.048101  ...   \n",
      "\n",
      "    Active Std   Active Max   Active Min  Idle Mean   Idle Std   Idle Max  \\\n",
      "0    -0.023426    -0.028885     -0.02277  -0.050212  -0.019815  -0.051132   \n",
      "1    -0.023426    -0.028885     -0.02277  -0.050212  -0.019815  -0.051132   \n",
      "2    -0.023426    -0.028885     -0.02277  -0.050212  -0.019815  -0.051132   \n",
      "3    -0.023426    -0.028885     -0.02277  -0.050212  -0.019815  -0.051132   \n",
      "4    -0.023426    -0.028885     -0.02277  -0.050212  -0.019815  -0.051132   \n",
      "\n",
      "    Idle Min  SimillarHTTP   Inbound    Label  \n",
      "0  -0.048556             0  0.155118  Portmap  \n",
      "1  -0.048556             0  0.155118  Portmap  \n",
      "2  -0.048556             0  0.155118  Portmap  \n",
      "3  -0.048556             0 -6.446721   BENIGN  \n",
      "4  -0.048556             0  0.155118  Portmap  \n",
      "\n",
      "[5 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df2 = pd.read_csv(r\"E:\\train\\sampled_data_2019.csv\")\n",
    "\n",
    "# Check for missing values and handle them (replace with mean or drop, depending on your preference)\n",
    "df2 = df2.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Check for infinite values and replace them with NaN\n",
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values after handling missing and infinite values\n",
    "df2 = df2.dropna()\n",
    "\n",
    "# Select only the numerical columns for normalization\n",
    "numerical_columns = df2.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create a copy of the DataFrame for printing the values before normalization\n",
    "original_df2 = df2.copy()\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply Z-score normalization to the numerical columns\n",
    "df2[numerical_columns] = scaler.fit_transform(df2[numerical_columns])\n",
    "\n",
    "# Save the normalized DataFrame to a new CSV file\n",
    "normalized_output_file_path = r\"E:\\train\\normalized_data_2019.csv\"\n",
    "df2.to_csv(normalized_output_file_path, index=False)\n",
    "\n",
    "# Index=False is used to prevent pandas from writing row indices to the CSV file\n",
    "\n",
    "# Print the original and normalized values\n",
    "print(\"Original Data:\")\n",
    "print(original_df2.head())  # Print the first few rows of the original DataFrame\n",
    "print(\"\\nNormalized Data:\")\n",
    "print(df2.head())  # Print the first few rows of the normalized DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357a906d-55e2-4a70-814b-8b297413ddd7",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b99378b5-d245-466f-9cf3-e14a28ff8209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['SimillarHTTP'], dtype='object')\n",
      "Extracted Features with Labels:\n",
      "   SVD_Component_1  SVD_Component_2  SVD_Component_3  SVD_Component_4  \\\n",
      "0        -0.152242         0.319137        -0.261851        -0.734376   \n",
      "1        -0.421562         0.399856         0.132190         0.133090   \n",
      "2        -0.452999         0.426368         0.133147         0.148206   \n",
      "3         4.074177       -16.688455        -3.000533        -0.459317   \n",
      "4        -0.483101         0.504240         0.176704         0.189453   \n",
      "\n",
      "   SVD_Component_5  SVD_Component_6  SVD_Component_7  SVD_Component_8  \\\n",
      "0        -0.360697         2.149862        -2.989077        -0.086121   \n",
      "1        -0.139571        -0.430144         0.587788         0.016944   \n",
      "2        -0.138249        -0.412661         0.544869         0.106093   \n",
      "3         0.109228        -1.590062         0.832358        -2.757621   \n",
      "4        -0.130204        -0.490064         0.584655         0.003027   \n",
      "\n",
      "   SVD_Component_9  SVD_Component_10    Label  \n",
      "0         1.146352         -0.147137  Portmap  \n",
      "1        -0.250706          0.209332  Portmap  \n",
      "2        -0.334559          0.250805  Portmap  \n",
      "3         1.766488         -1.217192   BENIGN  \n",
      "4        -0.159021         -0.217833  Portmap  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Load the normalized data from the CSV file\n",
    "normalized_data_path = r\"E:\\train\\normalized_data_2019.csv\"\n",
    "df2_normalized = pd.read_csv(normalized_data_path)\n",
    "\n",
    "# Separate labels from features\n",
    "labels = df2_normalized[' Label']\n",
    "# Drop non-numeric columns and other columns you don't need for SVD\n",
    "features = df2_normalized.drop(columns=[' Label',' Timestamp','Flow ID',' Source IP',' Destination IP'])\n",
    "\n",
    "# Check for non-numeric columns\n",
    "non_numeric_columns = features.select_dtypes(exclude=[np.number]).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)\n",
    "\n",
    "# Drop non-numeric columns\n",
    "features = features.select_dtypes(include=[np.number])\n",
    "\n",
    "# Perform SVD on the feature matrix\n",
    "n_components = 10  # Number of components to keep\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "extracted_features = svd.fit_transform(features)\n",
    "\n",
    "# Create a DataFrame for the extracted features\n",
    "df2_extracted_features = pd.DataFrame(extracted_features, columns=[f'SVD_Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Add the labels to the DataFrame\n",
    "df2_extracted_features[' Label'] = labels\n",
    "\n",
    "# Save the extracted features with labels to a new CSV file\n",
    "extracted_features_output_path = r\"E:\\train\\extracted_features_2019.csv\"\n",
    "df2_extracted_features.to_csv(extracted_features_output_path, index=False)\n",
    "\n",
    "# Print the values of the extracted features with labels\n",
    "print(\"Extracted Features with Labels:\")\n",
    "print(df2_extracted_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a82bc0-1f3e-4d88-979b-c86fb2aa43f3",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64373f53-c429-4735-84a5-214630faae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features with Encoded Labels:\n",
      "   SVD_Component_1  SVD_Component_2  SVD_Component_3  SVD_Component_4  \\\n",
      "0        -0.152242         0.319137        -0.261851        -0.734376   \n",
      "1        -0.421562         0.399856         0.132190         0.133090   \n",
      "2        -0.452999         0.426368         0.133147         0.148206   \n",
      "3         4.074177       -16.688455        -3.000533        -0.459317   \n",
      "4        -0.483101         0.504240         0.176704         0.189453   \n",
      "\n",
      "   SVD_Component_5  SVD_Component_6  SVD_Component_7  SVD_Component_8  \\\n",
      "0        -0.360697         2.149862        -2.989077        -0.086121   \n",
      "1        -0.139571        -0.430144         0.587788         0.016944   \n",
      "2        -0.138249        -0.412661         0.544869         0.106093   \n",
      "3         0.109228        -1.590062         0.832358        -2.757621   \n",
      "4        -0.130204        -0.490064         0.584655         0.003027   \n",
      "\n",
      "   SVD_Component_9  SVD_Component_10   Label  \n",
      "0         1.146352         -0.147137       1  \n",
      "1        -0.250706          0.209332       1  \n",
      "2        -0.334559          0.250805       1  \n",
      "3         1.766488         -1.217192       0  \n",
      "4        -0.159021         -0.217833       1  \n",
      "Encoded features saved to: E:\\train\\encoded_features_2019.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define label encoding dictionary\n",
    "label_encoding = {\n",
    "    'BENIGN': 0,\n",
    "    'Portmap': 1,\n",
    "}\n",
    "\n",
    "# Apply label encoding to the 'Label' column\n",
    "df2_extracted_features[' Label'] = df2_extracted_features[' Label'].map(label_encoding)\n",
    "\n",
    "# Print the values of the extracted features with encoded labels\n",
    "print(\"Extracted Features with Encoded Labels:\")\n",
    "print(df2_extracted_features.head())\n",
    "\n",
    "# Save the DataFrame with encoded labels to a new CSV file\n",
    "encoded_features_output_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df2_extracted_features.to_csv(encoded_features_output_path, index=False)\n",
    "\n",
    "# Print the path where the encoded features are saved\n",
    "print(f\"Encoded features saved to: {encoded_features_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a28900-c475-4b7b-ab87-eec81a14cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for each class:\n",
      " Label\n",
      "1    55448\n",
      "0     1455\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df2 = pd.read_csv(r\"E:\\train\\encoded_features_2019.csv\")\n",
    "\n",
    "# Get the value counts for the 'Label' column\n",
    "label_counts = df2[' Label'].value_counts()\n",
    "\n",
    "# Print the value counts\n",
    "print(\"Value counts for each class:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0ede9-520e-48a4-a938-866f0629a132",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ac15e0-f5ae-4ff9-b9eb-008d3a47d1c8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0007dae5-dbd8-4c5f-b986-6629e1b11ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9994728055531148\n",
      "F1 Score: 0.9997296566639631\n",
      "Precision: 0.9999098693105002\n",
      "Recall: 0.9995495089647716\n",
      "Detection Rate : 0.9995495089647716\n",
      "AUC Score: 0.9999926515646735\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       282\n",
      "           1       1.00      1.00      1.00     11099\n",
      "\n",
      "    accuracy                           1.00     11381\n",
      "   macro avg       0.99      1.00      0.99     11381\n",
      "weighted avg       1.00      1.00      1.00     11381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df2_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df2_extracted_features.drop(columns=[' Label'])\n",
    "y = df2_extracted_features[' Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = random_forest_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold the probabilities to get binary predictions\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Parse classification report to get F1 score, precision, recall, and detection rate\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "f1_score = classification_dict['1']['f1-score']\n",
    "precision = classification_dict['1']['precision']\n",
    "recall = classification_dict['1']['recall']\n",
    "detection_rate = classification_dict['1']['recall']\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Detection Rate : {detection_rate}\")\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b9211b-6e05-4854-9363-749c4c64c7d6",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5e7069d-933a-44bd-86a5-48cc2903ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9991213425885247\n",
      "F1 Score: 0.9995494683726797\n",
      "Precision: 0.9996395422186176\n",
      "Recall : 0.9994594107577259\n",
      "Detection Rate: 0.9994594107577259\n",
      "AUC Score: 0.9999316276017455\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       282\n",
      "           1       1.00      1.00      1.00     11099\n",
      "\n",
      "    accuracy                           1.00     11381\n",
      "   macro avg       0.99      0.99      0.99     11381\n",
      "weighted avg       1.00      1.00      1.00     11381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df2_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df2_extracted_features.drop(columns=[' Label'])\n",
    "y = df2_extracted_features[' Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Initialize the Support Vector Machine classifier\n",
    "svm_classifier = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Train the Support Vector Machine classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = svm_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold the probabilities to get binary predictions\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Parse classification report to get F1 score, precision, recall, and detection rate\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "f1_score = classification_dict['1']['f1-score']\n",
    "precision = classification_dict['1']['precision']\n",
    "recall = classification_dict['1']['recall']\n",
    "detection_rate = recall  # Detection rate is equivalent to recall in binary classification\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "print(f\"Detection Rate: {detection_rate}\")\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca3fbd-4a60-4690-bb82-ebfe29ada823",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ef1dd5e-0696-46cf-b6d8-64e9c17911a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9985941481416396\n",
      "F1 Score: 0.9992788244839088\n",
      "Precision: 0.9998196085505547\n",
      "Recall : 0.9987386251013605\n",
      "Detection Rate: 0.9987386251013605\n",
      "AUC Score: 0.999614047396769\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       282\n",
      "           1       1.00      1.00      1.00     11099\n",
      "\n",
      "    accuracy                           1.00     11381\n",
      "   macro avg       0.98      1.00      0.99     11381\n",
      "weighted avg       1.00      1.00      1.00     11381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df2_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df2_extracted_features.drop(columns=[' Label'])\n",
    "y = df2_extracted_features[' Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = lr_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold the probabilities to get binary predictions\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Parse classification report to get F1 score, precision, recall, and detection rate\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "f1_score = classification_dict['1']['f1-score']\n",
    "precision = classification_dict['1']['precision']\n",
    "recall = classification_dict['1']['recall']\n",
    "detection_rate = recall  # Detection rate is equivalent to recall in binary classification\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall : {recall}\")\n",
    "print(f\"Detection Rate: {detection_rate}\")\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2bb218-31fb-414b-a1b6-0234c7f58b41",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d2befc3-d0bb-4a66-85cd-559829fa3d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1139/1139 [==============================] - 7s 5ms/step - loss: 0.0245 - accuracy: 0.9968 - val_loss: 0.0065 - val_accuracy: 0.9991\n",
      "Epoch 2/10\n",
      "1139/1139 [==============================] - 4s 4ms/step - loss: 0.0090 - accuracy: 0.9989 - val_loss: 0.0119 - val_accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "1139/1139 [==============================] - 5s 4ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "1139/1139 [==============================] - 6s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "1139/1139 [==============================] - 6s 5ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
      "Epoch 6/10\n",
      "1139/1139 [==============================] - 5s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "1139/1139 [==============================] - 4s 4ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "1139/1139 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "Epoch 9/10\n",
      "1139/1139 [==============================] - 3s 3ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9997\n",
      "Epoch 10/10\n",
      "1139/1139 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
      "356/356 [==============================] - 1s 2ms/step\n",
      "Accuracy: 0.9992970740708198\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       282\n",
      "           1       1.00      1.00      1.00     11099\n",
      "\n",
      "    accuracy                           1.00     11381\n",
      "   macro avg       0.99      0.99      0.99     11381\n",
      "weighted avg       1.00      1.00      1.00     11381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df2_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df2_extracted_features.drop(columns=[' Label'])\n",
    "y = df2_extracted_features[' Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Define and train a Deep Neural Network (DNN) using TensorFlow\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_arms, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac97aac6-ed25-4b96-b6c9-30f059dac357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step\n",
      "Precision: 0.9997296566639632\n",
      "Recall: 0.9995495089647716\n",
      "F1 Score: 0.9996395746981437\n",
      "Detection Rate : 0.9995495089647716\n",
      "AUC Score: 0.9999239596692309\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, F1 score, detection rate (recall), and AUC score\n",
    "precision_recall_f1 = classification_report(y_test, np.argmax(y_pred_proba, axis=1), output_dict=True)\n",
    "precision = precision_recall_f1['1']['precision']\n",
    "recall = precision_recall_f1['1']['recall']\n",
    "f1_score = precision_recall_f1['1']['f1-score']\n",
    "detection_rate = recall\n",
    "\n",
    "# Calculate AUC score for each class separately\n",
    "auc_scores = []\n",
    "for i in range(len(np.unique(y_train))):\n",
    "    auc_scores.append(roc_auc_score((y_test == i).astype(int), y_pred_proba[:, i]))\n",
    "\n",
    "# Average AUC scores across all classes\n",
    "auc_score = np.mean(auc_scores)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Detection Rate : {detection_rate}\")\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54666816-72e1-456a-9d3e-4d8a20b6958b",
   "metadata": {},
   "source": [
    "# IDS-Anta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da515f8b-d3c1-4aa9-859b-63e3514bf724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423/1423 [==============================] - 6s 3ms/step - loss: 0.0247 - accuracy: 0.9979\n",
      "Accuracy: 0.9994728055531148\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       282\n",
      "           1       1.00      1.00      1.00     11099\n",
      "\n",
      "    accuracy                           1.00     11381\n",
      "   macro avg       0.99      1.00      0.99     11381\n",
      "weighted avg       1.00      1.00      1.00     11381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultiArmedBanditAntColonyOptimization:\n",
    "    def __init__(self, n_arms, n_ants):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_ants = n_ants\n",
    "        self.arms = [SVC(probability=True), LogisticRegression(), RandomForestClassifier(), self.create_dnn_model()]\n",
    "        self.pheromone = np.ones(n_arms)\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def create_dnn_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def choose_arm(self):\n",
    "        probabilities = self.pheromone / np.sum(self.pheromone)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.n_arms)\n",
    "        else:\n",
    "            return np.random.choice(self.n_arms, p=probabilities)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        self.pheromone[arm] += reward\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=[' Label'])\n",
    "y = df_extracted_features[' Label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Multi-Armed Bandit with Ant Colony Optimization\n",
    "n_arms = 4  # Number of classifiers\n",
    "n_ants = 10  # Number of ants\n",
    "bandit = MultiArmedBanditAntColonyOptimization(n_arms, n_ants)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "num_iterations = 10\n",
    "for _ in range(num_iterations):\n",
    "    for _ in range(n_ants):\n",
    "        arm = bandit.choose_arm()\n",
    "        classifier = bandit.arms[arm]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        if classifier.__class__.__name__ != 'Sequential':\n",
    "            y_pred = classifier.predict(X_train)\n",
    "            reward = accuracy_score(y_train, y_pred)\n",
    "        else:\n",
    "            _, accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "            reward = accuracy\n",
    "        bandit.update(arm, reward)\n",
    "\n",
    "# Choose the best classifier\n",
    "best_arm = np.argmax(bandit.pheromone)\n",
    "best_classifier = bandit.arms[best_arm]\n",
    "\n",
    "# Evaluate the best classifier on the test set\n",
    "if best_classifier.__class__.__name__ != 'Sequential':\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "else:\n",
    "    _, accuracy = best_classifier.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred = (best_classifier.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28678292-d0b5-48cc-8c9b-6699b8a90065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 1s 2ms/step\n",
      "356/356 [==============================] - 2s 5ms/step\n",
      "Evaluation Metrics :\n",
      "Precision: 0.999909893674536\n",
      "Recall: 0.9998198035859086\n",
      "F1 Score: 0.999864846600892\n",
      "AUC Score: 0.9999396150314481\n",
      "Detection Rate : 0.9998198035859086\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultiArmedBanditAntColonyOptimization:\n",
    "    def __init__(self, n_arms, n_ants):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_ants = n_ants\n",
    "        self.arms = [SVC(probability=True), LogisticRegression(), RandomForestClassifier(), self.create_dnn_model()]\n",
    "        self.pheromone = np.ones(n_arms)\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def create_dnn_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def choose_arm(self):\n",
    "        probabilities = self.pheromone / np.sum(self.pheromone)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.n_arms)\n",
    "        else:\n",
    "            return np.random.choice(self.n_arms, p=probabilities)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        self.pheromone[arm] += reward\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2019.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=[' Label'])\n",
    "y = df_extracted_features[' Label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Multi-Armed Bandit with Ant Colony Optimization\n",
    "n_arms = 4  # Number of classifiers\n",
    "n_ants = 10  # Number of ants\n",
    "bandit = MultiArmedBanditAntColonyOptimization(n_arms, n_ants)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "num_iterations = 10\n",
    "for _ in range(num_iterations):\n",
    "    for _ in range(n_ants):\n",
    "        arm = bandit.choose_arm()\n",
    "        classifier = bandit.arms[arm]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        if classifier.__class__.__name__ != 'Sequential':\n",
    "            y_pred = classifier.predict(X_train)\n",
    "            reward = accuracy_score(y_train, y_pred)\n",
    "        else:\n",
    "            _, accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "            reward = accuracy\n",
    "        bandit.update(arm, reward)\n",
    "\n",
    "# Choose the best classifier\n",
    "best_arm = np.argmax(bandit.pheromone)\n",
    "best_classifier = bandit.arms[best_arm]\n",
    "\n",
    "# Evaluate the best classifier on the test set\n",
    "if best_classifier.__class__.__name__ != 'Sequential':\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "else:\n",
    "    _, accuracy = best_classifier.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred = (best_classifier.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Compute detection rate (equivalent to recall)\n",
    "detection_rate = recall\n",
    "\n",
    "# Print precision, recall, detection rate, F1 score, and AUC score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Detection Rate:\", detection_rate)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
