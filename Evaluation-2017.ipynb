{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b47345-208d-4b24-a7db-8a2e9e129651",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27520693-9ef5-47dd-8067-0686caffbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f6240-1588-4b98-9777-676e8307782c",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adc9e7b-46a7-45e4-88bc-ce714a8dacf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>9101782</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>9100785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9100785</td>\n",
       "      <td>9100785</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>8971397</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>115</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>10.639288</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FTP-Patator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>11602599</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>371</td>\n",
       "      <td>11632</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>46.375000</td>\n",
       "      <td>131.168308</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>788.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788</td>\n",
       "      <td>788</td>\n",
       "      <td>6599964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6599964</td>\n",
       "      <td>6599964</td>\n",
       "      <td>DoS GoldenEye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.899495</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FTP-Patator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8193</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61376</th>\n",
       "      <td>49158</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61377</th>\n",
       "      <td>80</td>\n",
       "      <td>11795861</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>442</td>\n",
       "      <td>11632</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>156.270599</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>6791853.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6791853</td>\n",
       "      <td>6791853</td>\n",
       "      <td>DoS GoldenEye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61378</th>\n",
       "      <td>54614</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61379</th>\n",
       "      <td>22</td>\n",
       "      <td>13544213</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>2008</td>\n",
       "      <td>2745</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>95.619048</td>\n",
       "      <td>140.045163</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SSH-Patator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61380</th>\n",
       "      <td>80</td>\n",
       "      <td>73050914</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>11601</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>36100000.0</td>\n",
       "      <td>42900000.0</td>\n",
       "      <td>66400000</td>\n",
       "      <td>5784815</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61381 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0                    80        9101782                  5   \n",
       "1                    21        8971397                  9   \n",
       "2                    80       11602599                  8   \n",
       "3                    21            250                  2   \n",
       "4                  8193             42                  1   \n",
       "...                 ...            ...                ...   \n",
       "61376             49158             48                  1   \n",
       "61377                80       11795861                  8   \n",
       "61378             54614              2                  3   \n",
       "61379                22       13544213                 21   \n",
       "61380                80       73050914                  8   \n",
       "\n",
       "       Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                           0                           30   \n",
       "1                          15                          115   \n",
       "2                           5                          371   \n",
       "3                           1                           14   \n",
       "4                           1                            0   \n",
       "...                       ...                          ...   \n",
       "61376                       1                            2   \n",
       "61377                       5                          442   \n",
       "61378                       0                           18   \n",
       "61379                      32                         2008   \n",
       "61380                       7                           56   \n",
       "\n",
       "       Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                                0                      6   \n",
       "1                              188                     27   \n",
       "2                            11632                    371   \n",
       "3                                0                     14   \n",
       "4                                6                      0   \n",
       "...                            ...                    ...   \n",
       "61376                            6                      2   \n",
       "61377                        11632                    442   \n",
       "61378                            0                      6   \n",
       "61379                         2745                    640   \n",
       "61380                        11601                     20   \n",
       "\n",
       "       Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                          6                6.000000               0.000000   \n",
       "1                          0               12.777778              10.639288   \n",
       "2                          0               46.375000             131.168308   \n",
       "3                          0                7.000000               9.899495   \n",
       "4                          0                0.000000               0.000000   \n",
       "...                      ...                     ...                    ...   \n",
       "61376                      2                2.000000               0.000000   \n",
       "61377                      0               55.250000             156.270599   \n",
       "61378                      6                6.000000               0.000000   \n",
       "61379                      0               95.619048             140.045163   \n",
       "61380                      0                7.000000               5.656854   \n",
       "\n",
       "       ...  min_seg_size_forward  Active Mean  Active Std  Active Max  \\\n",
       "0      ...                    20        997.0         0.0         997   \n",
       "1      ...                    32          0.0         0.0           0   \n",
       "2      ...                    32        788.0         0.0         788   \n",
       "3      ...                    32          0.0         0.0           0   \n",
       "4      ...                    40          0.0         0.0           0   \n",
       "...    ...                   ...          ...         ...         ...   \n",
       "61376  ...                    24          0.0         0.0           0   \n",
       "61377  ...                    32        949.0         0.0         949   \n",
       "61378  ...                    20          0.0         0.0           0   \n",
       "61379  ...                    32          0.0         0.0           0   \n",
       "61380  ...                    20       1000.0         0.0        1000   \n",
       "\n",
       "       Active Min   Idle Mean    Idle Std  Idle Max  Idle Min          Label  \n",
       "0             997   9100785.0         0.0   9100785   9100785           DDoS  \n",
       "1               0         0.0         0.0         0         0    FTP-Patator  \n",
       "2             788   6599964.0         0.0   6599964   6599964  DoS GoldenEye  \n",
       "3               0         0.0         0.0         0         0    FTP-Patator  \n",
       "4               0         0.0         0.0         0         0       PortScan  \n",
       "...           ...         ...         ...       ...       ...            ...  \n",
       "61376           0         0.0         0.0         0         0       PortScan  \n",
       "61377         949   6791853.0         0.0   6791853   6791853  DoS GoldenEye  \n",
       "61378           0         0.0         0.0         0         0         BENIGN  \n",
       "61379           0         0.0         0.0         0         0    SSH-Patator  \n",
       "61380        1000  36100000.0  42900000.0  66400000   5784815           DDoS  \n",
       "\n",
       "[61381 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(r\"E:\\train\\samplled_dataset.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3c1caa-ca9d-494f-a635-1efd4aec9321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Destination Port                2877\n",
       "Flow Duration                  41884\n",
       "Total Fwd Packets                134\n",
       "Total Backward Packets           149\n",
       "Total Length of Fwd Packets     1901\n",
       "                               ...  \n",
       "Idle Mean                       5911\n",
       "Idle Std                        1106\n",
       "Idle Max                        5661\n",
       "Idle Min                        9257\n",
       "Label                             15\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Unique Values\n",
    "df1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5280e966-b59f-4615-a2e4-268cde639c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Destination Port               0\n",
       "Flow Duration                  0\n",
       "Total Fwd Packets              0\n",
       "Total Backward Packets         0\n",
       "Total Length of Fwd Packets    0\n",
       "                              ..\n",
       "Idle Mean                      0\n",
       "Idle Std                       0\n",
       "Idle Max                       0\n",
       "Idle Min                       0\n",
       "Label                          0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the null values\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa9851f-a7d1-4f01-9509-1718a9378992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to: E:\\train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df1 = pd.read_csv(r\"E:\\train\\samplled_dataset.csv\")\n",
    "\n",
    "# Extract the label column\n",
    "labels = df1['Label']\n",
    "\n",
    "# Drop the label column before handling missing values\n",
    "df1.drop(columns=['Label'], inplace=True)\n",
    "\n",
    "# Fill missing values with the mean of their respective columns\n",
    "df1_cleaned = df1.fillna(df1.mean())\n",
    "\n",
    "# Add the label column back to the cleaned DataFrame\n",
    "df1_cleaned['Label'] = labels\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = r\"E:\\train\"\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file in the output directory\n",
    "df1_cleaned.to_csv(output_dir + \"\\\\cleaned_dataset_2017.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaned and saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6bf803-8d5f-4e31-b3d8-fb995e244225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>9101782</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>9100785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9100785</td>\n",
       "      <td>9100785</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>8971397</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>115</td>\n",
       "      <td>188</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>10.639288</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FTP-Patator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>11602599</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>371</td>\n",
       "      <td>11632</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "      <td>46.375000</td>\n",
       "      <td>131.168308</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>788.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788</td>\n",
       "      <td>788</td>\n",
       "      <td>6599964.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6599964</td>\n",
       "      <td>6599964</td>\n",
       "      <td>DoS GoldenEye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.899495</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FTP-Patator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8193</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61376</th>\n",
       "      <td>49158</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PortScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61377</th>\n",
       "      <td>80</td>\n",
       "      <td>11795861</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>442</td>\n",
       "      <td>11632</td>\n",
       "      <td>442</td>\n",
       "      <td>0</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>156.270599</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>949</td>\n",
       "      <td>949</td>\n",
       "      <td>6791853.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6791853</td>\n",
       "      <td>6791853</td>\n",
       "      <td>DoS GoldenEye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61378</th>\n",
       "      <td>54614</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61379</th>\n",
       "      <td>22</td>\n",
       "      <td>13544213</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>2008</td>\n",
       "      <td>2745</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>95.619048</td>\n",
       "      <td>140.045163</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SSH-Patator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61380</th>\n",
       "      <td>80</td>\n",
       "      <td>73050914</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>11601</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>36100000.0</td>\n",
       "      <td>42900000.0</td>\n",
       "      <td>66400000</td>\n",
       "      <td>5784815</td>\n",
       "      <td>DDoS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61381 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Destination Port  Flow Duration  Total Fwd Packets  \\\n",
       "0                    80        9101782                  5   \n",
       "1                    21        8971397                  9   \n",
       "2                    80       11602599                  8   \n",
       "3                    21            250                  2   \n",
       "4                  8193             42                  1   \n",
       "...                 ...            ...                ...   \n",
       "61376             49158             48                  1   \n",
       "61377                80       11795861                  8   \n",
       "61378             54614              2                  3   \n",
       "61379                22       13544213                 21   \n",
       "61380                80       73050914                  8   \n",
       "\n",
       "       Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "0                           0                           30   \n",
       "1                          15                          115   \n",
       "2                           5                          371   \n",
       "3                           1                           14   \n",
       "4                           1                            0   \n",
       "...                       ...                          ...   \n",
       "61376                       1                            2   \n",
       "61377                       5                          442   \n",
       "61378                       0                           18   \n",
       "61379                      32                         2008   \n",
       "61380                       7                           56   \n",
       "\n",
       "       Total Length of Bwd Packets  Fwd Packet Length Max  \\\n",
       "0                                0                      6   \n",
       "1                              188                     27   \n",
       "2                            11632                    371   \n",
       "3                                0                     14   \n",
       "4                                6                      0   \n",
       "...                            ...                    ...   \n",
       "61376                            6                      2   \n",
       "61377                        11632                    442   \n",
       "61378                            0                      6   \n",
       "61379                         2745                    640   \n",
       "61380                        11601                     20   \n",
       "\n",
       "       Fwd Packet Length Min  Fwd Packet Length Mean  Fwd Packet Length Std  \\\n",
       "0                          6                6.000000               0.000000   \n",
       "1                          0               12.777778              10.639288   \n",
       "2                          0               46.375000             131.168308   \n",
       "3                          0                7.000000               9.899495   \n",
       "4                          0                0.000000               0.000000   \n",
       "...                      ...                     ...                    ...   \n",
       "61376                      2                2.000000               0.000000   \n",
       "61377                      0               55.250000             156.270599   \n",
       "61378                      6                6.000000               0.000000   \n",
       "61379                      0               95.619048             140.045163   \n",
       "61380                      0                7.000000               5.656854   \n",
       "\n",
       "       ...  min_seg_size_forward  Active Mean  Active Std  Active Max  \\\n",
       "0      ...                    20        997.0         0.0         997   \n",
       "1      ...                    32          0.0         0.0           0   \n",
       "2      ...                    32        788.0         0.0         788   \n",
       "3      ...                    32          0.0         0.0           0   \n",
       "4      ...                    40          0.0         0.0           0   \n",
       "...    ...                   ...          ...         ...         ...   \n",
       "61376  ...                    24          0.0         0.0           0   \n",
       "61377  ...                    32        949.0         0.0         949   \n",
       "61378  ...                    20          0.0         0.0           0   \n",
       "61379  ...                    32          0.0         0.0           0   \n",
       "61380  ...                    20       1000.0         0.0        1000   \n",
       "\n",
       "       Active Min   Idle Mean    Idle Std  Idle Max  Idle Min          Label  \n",
       "0             997   9100785.0         0.0   9100785   9100785           DDoS  \n",
       "1               0         0.0         0.0         0         0    FTP-Patator  \n",
       "2             788   6599964.0         0.0   6599964   6599964  DoS GoldenEye  \n",
       "3               0         0.0         0.0         0         0    FTP-Patator  \n",
       "4               0         0.0         0.0         0         0       PortScan  \n",
       "...           ...         ...         ...       ...       ...            ...  \n",
       "61376           0         0.0         0.0         0         0       PortScan  \n",
       "61377         949   6791853.0         0.0   6791853   6791853  DoS GoldenEye  \n",
       "61378           0         0.0         0.0         0         0         BENIGN  \n",
       "61379           0         0.0         0.0         0         0    SSH-Patator  \n",
       "61380        1000  36100000.0  42900000.0  66400000   5784815           DDoS  \n",
       "\n",
       "[61381 rows x 79 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(r\"E:\\train\\cleaned_dataset_2017.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a039f9d-c789-402c-978b-25db10ae3b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for each class:\n",
      "Label\n",
      "DDoS                        6666\n",
      "FTP-Patator                 6666\n",
      "DoS GoldenEye               6666\n",
      "PortScan                    6666\n",
      "BENIGN                      6666\n",
      "DoS Hulk                    6666\n",
      "SSH-Patator                 5897\n",
      "DoS slowloris               5796\n",
      "DoS Slowhttptest            5499\n",
      "Bot                         1966\n",
      "Web Attack Brute Force      1507\n",
      "Web Attack XSS               652\n",
      "Infiltration                  36\n",
      "Web Attack Sql Injection      21\n",
      "Heartbleed                    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df1 = pd.read_csv(r\"E:\\train\\cleaned_dataset_2017.csv\")\n",
    "\n",
    "# Get the value counts for the 'Label' column\n",
    "label_counts = df1['Label'].value_counts()\n",
    "\n",
    "# Print the value counts\n",
    "print(\"Value counts for each class:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f3894-02f2-42d9-a11b-e84267edb23f",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4e6bf8-d957-4f01-b64f-065a7ba1b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
      "0                80        9101782                  5                       0   \n",
      "1                21        8971397                  9                      15   \n",
      "2                80       11602599                  8                       5   \n",
      "3                21            250                  2                       1   \n",
      "4              8193             42                  1                       1   \n",
      "\n",
      "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
      "0                           30                            0   \n",
      "1                          115                          188   \n",
      "2                          371                        11632   \n",
      "3                           14                            0   \n",
      "4                            0                            6   \n",
      "\n",
      "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
      "0                      6                      6                6.000000   \n",
      "1                     27                      0               12.777778   \n",
      "2                    371                      0               46.375000   \n",
      "3                     14                      0                7.000000   \n",
      "4                      0                      0                0.000000   \n",
      "\n",
      "   Fwd Packet Length Std  ...  min_seg_size_forward  Active Mean  Active Std  \\\n",
      "0               0.000000  ...                    20        997.0         0.0   \n",
      "1              10.639288  ...                    32          0.0         0.0   \n",
      "2             131.168308  ...                    32        788.0         0.0   \n",
      "3               9.899495  ...                    32          0.0         0.0   \n",
      "4               0.000000  ...                    40          0.0         0.0   \n",
      "\n",
      "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
      "0         997         997  9100785.0       0.0   9100785   9100785   \n",
      "1           0           0        0.0       0.0         0         0   \n",
      "2         788         788  6599964.0       0.0   6599964   6599964   \n",
      "3           0           0        0.0       0.0         0         0   \n",
      "4           0           0        0.0       0.0         0         0   \n",
      "\n",
      "           Label  \n",
      "0           DDoS  \n",
      "1    FTP-Patator  \n",
      "2  DoS GoldenEye  \n",
      "3    FTP-Patator  \n",
      "4       PortScan  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "\n",
      "Normalized Data:\n",
      "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
      "0         -0.256199      -0.391068          -0.026514               -0.081724   \n",
      "1         -0.262276      -0.394572           0.028462                0.120721   \n",
      "2         -0.256199      -0.323864           0.014718               -0.014243   \n",
      "3         -0.262276      -0.635652          -0.067746               -0.068228   \n",
      "4          0.579324      -0.635658          -0.081490               -0.068228   \n",
      "\n",
      "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
      "0                    -0.034730                    -0.032092   \n",
      "1                    -0.030567                    -0.030921   \n",
      "2                    -0.018030                     0.040387   \n",
      "3                    -0.035514                    -0.032092   \n",
      "4                    -0.036199                    -0.032055   \n",
      "\n",
      "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
      "0              -0.294190              -0.061846               -0.234317   \n",
      "1              -0.255466              -0.108786               -0.197611   \n",
      "2               0.378862              -0.108786               -0.015660   \n",
      "3              -0.279438              -0.108786               -0.228901   \n",
      "4              -0.305254              -0.108786               -0.266811   \n",
      "\n",
      "   Fwd Packet Length Std  ...  min_seg_size_forward  Active Mean  Active Std  \\\n",
      "0              -0.333946  ...             -1.540951    -0.308653   -0.183256   \n",
      "1              -0.269083  ...              0.346470    -0.309247   -0.183256   \n",
      "2               0.465731  ...              0.346470    -0.308777   -0.183256   \n",
      "3              -0.273593  ...              0.346470    -0.309247   -0.183256   \n",
      "4              -0.333946  ...              1.604751    -0.309247   -0.183256   \n",
      "\n",
      "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
      "0   -0.316624   -0.251292  -0.190121 -0.259128 -0.244495 -0.147067   \n",
      "1   -0.317110   -0.251935  -0.480105 -0.259128 -0.521777 -0.438458   \n",
      "2   -0.316726   -0.251427  -0.269806 -0.259128 -0.320690 -0.227139   \n",
      "3   -0.317110   -0.251935  -0.480105 -0.259128 -0.521777 -0.438458   \n",
      "4   -0.317110   -0.251935  -0.480105 -0.259128 -0.521777 -0.438458   \n",
      "\n",
      "           Label  \n",
      "0           DDoS  \n",
      "1    FTP-Patator  \n",
      "2  DoS GoldenEye  \n",
      "3    FTP-Patator  \n",
      "4       PortScan  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df1 = pd.read_csv(r\"E:\\train\\cleaned_dataset_2017.csv\")\n",
    "\n",
    "# Check for missing values and handle them (replace with mean or drop, depending on your preference)\n",
    "df1 = df1.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Check for infinite values and replace them with NaN\n",
    "df1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values after handling missing and infinite values\n",
    "df1 = df1.dropna()\n",
    "\n",
    "# Select only the numerical columns for normalization\n",
    "numerical_columns = df1.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create a copy of the DataFrame for printing the values before normalization\n",
    "original_df1 = df1.copy()\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply Z-score normalization to the numerical columns\n",
    "df1[numerical_columns] = scaler.fit_transform(df1[numerical_columns])\n",
    "\n",
    "# Save the normalized DataFrame to a new CSV file\n",
    "normalized_output_file_path = r\"E:\\train\\normalized_data_2017.csv\"\n",
    "df1.to_csv(normalized_output_file_path, index=False)\n",
    "\n",
    "# Index=False is used to prevent pandas from writing row indices to the CSV file\n",
    "\n",
    "# Print the original and normalized values\n",
    "print(\"Original Data:\")\n",
    "print(original_df1.head())  # Print the first few rows of the original DataFrame\n",
    "print(\"\\nNormalized Data:\")\n",
    "print(df1.head())  # Print the first few rows of the normalized DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89c43e-35d3-4336-8f14-1abec42155ff",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45daa940-fa81-40ca-8d04-7c913e2d2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features with Labels:\n",
      "   SVD_Component_1  SVD_Component_2  SVD_Component_3  SVD_Component_4  \\\n",
      "0        -1.469285        -0.375134         0.711321         1.261320   \n",
      "1        -2.070003         0.263182         0.623799        -1.114233   \n",
      "2         1.162156         1.590397        -4.815890        -0.870785   \n",
      "3        -2.249284        -0.571253         1.313688         2.369248   \n",
      "4        -2.583720        -0.111071         0.584528        -1.133595   \n",
      "\n",
      "   SVD_Component_5  SVD_Component_6  SVD_Component_7  SVD_Component_8  \\\n",
      "0        -0.618266         0.013010        -0.832905         0.944520   \n",
      "1        -0.330607        -1.084432         0.600620        -0.016442   \n",
      "2        -0.278490         0.091140         1.166108        -1.183645   \n",
      "3         0.167687         1.031189        -0.447211        -1.481899   \n",
      "4        -0.257077        -0.758142         0.658240        -0.074086   \n",
      "\n",
      "   SVD_Component_9  SVD_Component_10          Label  \n",
      "0         0.219948         -0.072696           DDoS  \n",
      "1        -0.355603          0.017129    FTP-Patator  \n",
      "2         0.169183          0.115436  DoS GoldenEye  \n",
      "3         0.898452          0.074048    FTP-Patator  \n",
      "4        -0.487254          0.044066       PortScan  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Load the normalized data from the CSV file\n",
    "normalized_data_path = r\"E:\\train\\normalized_data_2017.csv\"\n",
    "df1_normalized = pd.read_csv(normalized_data_path)\n",
    "\n",
    "# Separate labels from features\n",
    "labels = df1_normalized['Label']\n",
    "features = df1_normalized.drop(columns=['Label'])\n",
    "\n",
    "# Perform SVD on the feature matrix\n",
    "n_components = 10  # Number of components to keep\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "extracted_features = svd.fit_transform(features)\n",
    "\n",
    "# Create a DataFrame for the extracted features\n",
    "df1_extracted_features = pd.DataFrame(extracted_features, columns=[f'SVD_Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "# Add the labels to the DataFrame\n",
    "df1_extracted_features['Label'] = labels\n",
    "\n",
    "# Save the extracted features with labels to a new CSV file\n",
    "extracted_features_output_path = r\"E:\\train\\extracted_features_2017.csv\"\n",
    "df1_extracted_features.to_csv(extracted_features_output_path, index=False)\n",
    "\n",
    "# Print the values of the extracted features with labels\n",
    "print(\"Extracted Features with Labels:\")\n",
    "print(df1_extracted_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8085b-319f-4777-acb3-775080d6a5af",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86b1ccf8-d8c2-4da0-8480-b7a8073e0dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Features with Encoded Labels:\n",
      "   SVD_Component_1  SVD_Component_2  SVD_Component_3  SVD_Component_4  \\\n",
      "0        -1.469285        -0.375134         0.711321         1.261320   \n",
      "1        -2.070003         0.263182         0.623799        -1.114233   \n",
      "2         1.162156         1.590397        -4.815890        -0.870785   \n",
      "3        -2.249284        -0.571253         1.313688         2.369248   \n",
      "4        -2.583720        -0.111071         0.584528        -1.133595   \n",
      "\n",
      "   SVD_Component_5  SVD_Component_6  SVD_Component_7  SVD_Component_8  \\\n",
      "0        -0.618266         0.013010        -0.832905         0.944520   \n",
      "1        -0.330607        -1.084432         0.600620        -0.016442   \n",
      "2        -0.278490         0.091140         1.166108        -1.183645   \n",
      "3         0.167687         1.031189        -0.447211        -1.481899   \n",
      "4        -0.257077        -0.758142         0.658240        -0.074086   \n",
      "\n",
      "   SVD_Component_9  SVD_Component_10  Label  \n",
      "0         0.219948         -0.072696      1  \n",
      "1        -0.355603          0.017129      1  \n",
      "2         0.169183          0.115436      0  \n",
      "3         0.898452          0.074048      1  \n",
      "4        -0.487254          0.044066      0  \n",
      "Encoded features saved to: E:\\train\\encoded_features_2017.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define label encoding dictionary\n",
    "label_encoding = {\n",
    "    'BENIGN': 0,\n",
    "    'PortScan': 0,\n",
    "    'Infiltration': 1,\n",
    "    'DDoS': 1,\n",
    "    'FTP-Patator': 1,\n",
    "    'DoS GoldenEye': 0,\n",
    "    'DoS Hulk': 1,\n",
    "    'SSH-Patator': 1,\n",
    "    'DoS slowloris': 1,\n",
    "    'DoS Slowhttptest': 1,\n",
    "    'Bot': 1,\n",
    "    'Web Attack Brute Force': 1,\n",
    "    'Web Attack XSS': 1,\n",
    "    'Web Attack Sql Injection': 1,\n",
    "    'Heartbleed': 1\n",
    "}\n",
    "\n",
    "# Apply label encoding to the 'Label' column\n",
    "df1_extracted_features['Label'] = df1_extracted_features['Label'].map(label_encoding)\n",
    "\n",
    "# Print the values of the extracted features with encoded labels\n",
    "print(\"Extracted Features with Encoded Labels:\")\n",
    "print(df1_extracted_features.head())\n",
    "\n",
    "# Save the DataFrame with encoded labels to a new CSV file\n",
    "encoded_features_output_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df1_extracted_features.to_csv(encoded_features_output_path, index=False)\n",
    "\n",
    "# Print the path where the encoded features are saved\n",
    "print(f\"Encoded features saved to: {encoded_features_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb3452b7-a0a0-4c34-ab9a-e9a4df38d09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for each class:\n",
      "Label\n",
      "1    41346\n",
      "0    19990\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df1 = pd.read_csv(r\"E:\\train\\encoded_features_2017.csv\")\n",
    "\n",
    "# Get the value counts for the 'Label' column\n",
    "label_counts = df1['Label'].value_counts()\n",
    "\n",
    "# Print the value counts\n",
    "print(\"Value counts for each class:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310c8c7-536a-4f26-be83-07bf1e1c72d1",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62513036-e319-404a-8e85-70668c0dfb73",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbf14b3-18d2-4c9b-8a2a-4c667e95bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9960873818063254\n",
      "F1 Score: 0.9970866715222142\n",
      "Detection Rate : 0.9974499089253187\n",
      "Precision: 0.9967236985802694\n",
      "Recall: 0.9974499089253187\n",
      "AUC Score: 0.9995559403590686\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4033\n",
      "           1       1.00      1.00      1.00      8235\n",
      "\n",
      "    accuracy                           1.00     12268\n",
      "   macro avg       1.00      1.00      1.00     12268\n",
      "weighted avg       1.00      1.00      1.00     12268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=['Label'])\n",
    "y = df_extracted_features['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = random_forest_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold the probabilities to get binary predictions\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Parse classification report to get F1 score and detection rate\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "f1_score = classification_dict['1']['f1-score']\n",
    "detection_rate = classification_dict['1']['recall']\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Detection Rate : {detection_rate}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83d3e5-58dd-4dae-935e-89ee63b4b0cf",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b272d7ae-8604-4c69-a4ce-bc6ab6cdd5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9367460058689273\n",
      "F1 Score: 0.9534269595486736\n",
      "Detection Rate : 0.964541590771099\n",
      "Precision: 0.9425655630710811\n",
      "Recall: 0.964541590771099\n",
      "AUC Score: 0.9687911554207239\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      4033\n",
      "           1       0.94      0.96      0.95      8235\n",
      "\n",
      "    accuracy                           0.94     12268\n",
      "   macro avg       0.93      0.92      0.93     12268\n",
      "weighted avg       0.94      0.94      0.94     12268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=['Label'])\n",
    "y = df_extracted_features['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = svm_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold the probabilities to get binary predictions\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Parse classification report to get F1 score and detection rate\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "f1_score = classification_dict['1']['f1-score']\n",
    "detection_rate = classification_dict['1']['recall']\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Detection Rate : {detection_rate}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8af619-8f91-41d1-b6ad-f8e5028b75b6",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1dd9a32-fd69-46c1-b6d8-66cf9f1acace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6928594717965438\n",
      "F1 Score: 0.7926480299361656\n",
      "Detection Rate : 0.8745598057073467\n",
      "Precision: 0.7247660259635705\n",
      "Recall: 0.8745598057073467\n",
      "AUC Score: 0.7838954008904376\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.32      0.41      4033\n",
      "           1       0.72      0.87      0.79      8235\n",
      "\n",
      "    accuracy                           0.69     12268\n",
      "   macro avg       0.64      0.60      0.60     12268\n",
      "weighted avg       0.67      0.69      0.67     12268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=['Label'])\n",
    "y = df_extracted_features['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logistic_regression_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "logistic_regression_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = logistic_regression_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold the probabilities to get binary predictions\n",
    "threshold = 0.5\n",
    "y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Parse classification report to get F1 score and detection rate\n",
    "classification_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "f1_score = classification_dict['1']['f1-score']\n",
    "detection_rate = classification_dict['1']['recall']\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Detection Rate : {detection_rate}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"AUC Score: {auc_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ca602-701a-46ca-a122-5cadb9b864d9",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6003efe3-b6ff-4e3b-917d-f2e965575f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1227/1227 [==============================] - 5s 3ms/step - loss: 0.1909 - accuracy: 0.9341 - val_loss: 0.1557 - val_accuracy: 0.9598\n",
      "Epoch 2/10\n",
      "1227/1227 [==============================] - 4s 3ms/step - loss: 0.1058 - accuracy: 0.9686 - val_loss: 0.1353 - val_accuracy: 0.9725\n",
      "Epoch 3/10\n",
      "1227/1227 [==============================] - 4s 3ms/step - loss: 0.0900 - accuracy: 0.9754 - val_loss: 0.0757 - val_accuracy: 0.9767\n",
      "Epoch 4/10\n",
      "1227/1227 [==============================] - 3s 3ms/step - loss: 0.0723 - accuracy: 0.9768 - val_loss: 0.0636 - val_accuracy: 0.9798\n",
      "Epoch 5/10\n",
      "1227/1227 [==============================] - 5s 4ms/step - loss: 0.0746 - accuracy: 0.9788 - val_loss: 0.0972 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "1227/1227 [==============================] - 4s 3ms/step - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.0577 - val_accuracy: 0.9813\n",
      "Epoch 7/10\n",
      "1227/1227 [==============================] - 4s 3ms/step - loss: 0.0614 - accuracy: 0.9804 - val_loss: 0.0651 - val_accuracy: 0.9795\n",
      "Epoch 8/10\n",
      "1227/1227 [==============================] - 3s 3ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 0.0525 - val_accuracy: 0.9872\n",
      "Epoch 9/10\n",
      "1227/1227 [==============================] - 3s 3ms/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.0509 - val_accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "1227/1227 [==============================] - 4s 3ms/step - loss: 0.0499 - accuracy: 0.9830 - val_loss: 0.0515 - val_accuracy: 0.9799\n",
      "384/384 [==============================] - 1s 2ms/step\n",
      "Accuracy: 0.9802738832735572\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4033\n",
      "           1       0.99      0.98      0.99      8235\n",
      "\n",
      "    accuracy                           0.98     12268\n",
      "   macro avg       0.98      0.98      0.98     12268\n",
      "weighted avg       0.98      0.98      0.98     12268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "class ThompsonSamplingMultiArmedBandit:\n",
    "    def __init__(self, n_arms):\n",
    "        self.n_arms = n_arms\n",
    "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
    "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
    "\n",
    "    def choose_arm(self):\n",
    "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
    "        return np.argmax(samples)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        if reward == 1:\n",
    "            self.alpha[arm] += 1\n",
    "        else:\n",
    "            self.beta[arm] += 1\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=['Label'])\n",
    "y = df_extracted_features['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multi-Armed Bandit\n",
    "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
    "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "for _ in range(len(X_train)):\n",
    "    arm = bandit.choose_arm()\n",
    "    reward = 1 if y_train.iloc[_] == arm else 0\n",
    "    bandit.update(arm, reward)\n",
    "\n",
    "# Define and train a Deep Neural Network (DNN) using TensorFlow\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_arms, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a9942d-4f84-4184-b253-88734d6d647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 1s 1ms/step\n",
      "Precision: 0.9852492990369377\n",
      "Recall: 0.9814207650273225\n",
      "F1 Score: 0.9833313055116194\n",
      "Detection Rate (Recall): 0.9814207650273225\n",
      "AUC Score: 0.9966208274750913\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the testing set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, F1 score, detection rate (recall), and AUC score\n",
    "precision_recall_f1 = classification_report(y_test, np.argmax(y_pred_proba, axis=1), output_dict=True)\n",
    "precision = precision_recall_f1['1']['precision']\n",
    "recall = precision_recall_f1['1']['recall']\n",
    "f1_score = precision_recall_f1['1']['f1-score']\n",
    "detection_rate = recall\n",
    "\n",
    "# Calculate AUC score for each class separately\n",
    "auc_scores = []\n",
    "for i in range(len(np.unique(y_train))):\n",
    "    auc_scores.append(roc_auc_score((y_test == i).astype(int), y_pred_proba[:, i]))\n",
    "\n",
    "# Average AUC scores across all classes\n",
    "auc_score = np.mean(auc_scores)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Detection Rate (Recall): {detection_rate}\")\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b3c7b-f6b3-4e4f-874a-5f399d3ee608",
   "metadata": {},
   "source": [
    "# IDS-Anta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4ae073a-b959-4ac3-ae9c-e8be0c76cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534/1534 [==============================] - 5s 2ms/step - loss: 0.1956 - accuracy: 0.9308\n",
      "1534/1534 [==============================] - 3s 2ms/step - loss: 0.0968 - accuracy: 0.9709\n",
      "Accuracy: 0.9957613302901859\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4033\n",
      "           1       1.00      1.00      1.00      8235\n",
      "\n",
      "    accuracy                           1.00     12268\n",
      "   macro avg       1.00      1.00      1.00     12268\n",
      "weighted avg       1.00      1.00      1.00     12268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultiArmedBanditAntColonyOptimization:\n",
    "    def __init__(self, n_arms, n_ants):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_ants = n_ants\n",
    "        self.arms = [SVC(probability=True), LogisticRegression(), RandomForestClassifier(), self.create_dnn_model()]\n",
    "        self.pheromone = np.ones(n_arms)\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def create_dnn_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def choose_arm(self):\n",
    "        probabilities = self.pheromone / np.sum(self.pheromone)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.n_arms)\n",
    "        else:\n",
    "            return np.random.choice(self.n_arms, p=probabilities)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        self.pheromone[arm] += reward\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=['Label'])\n",
    "y = df_extracted_features['Label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Multi-Armed Bandit with Ant Colony Optimization\n",
    "n_arms = 4  # Number of classifiers\n",
    "n_ants = 10  # Number of ants\n",
    "bandit = MultiArmedBanditAntColonyOptimization(n_arms, n_ants)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "num_iterations = 10\n",
    "for _ in range(num_iterations):\n",
    "    for _ in range(n_ants):\n",
    "        arm = bandit.choose_arm()\n",
    "        classifier = bandit.arms[arm]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        if classifier.__class__.__name__ != 'Sequential':\n",
    "            y_pred = classifier.predict(X_train)\n",
    "            reward = accuracy_score(y_train, y_pred)\n",
    "        else:\n",
    "            _, accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "            reward = accuracy\n",
    "        bandit.update(arm, reward)\n",
    "\n",
    "# Choose the best classifier\n",
    "best_arm = np.argmax(bandit.pheromone)\n",
    "best_classifier = bandit.arms[best_arm]\n",
    "\n",
    "# Evaluate the best classifier on the test set\n",
    "if best_classifier.__class__.__name__ != 'Sequential':\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "else:\n",
    "    _, accuracy = best_classifier.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred = (best_classifier.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204590e4-8f0c-43a9-9a43-9ba2549bafa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 2s 4ms/step\n",
      "384/384 [==============================] - 0s 1ms/step\n",
      "384/384 [==============================] - 1s 1ms/step\n",
      "Evaluation Metrics :\n",
      "Precision: 0.9463008559033884\n",
      "Recall: 0.9800850030358227\n",
      "F1 Score: 0.9628966833691243\n",
      "AUC Score: 0.9727132908212769\n",
      "Detection Rate : 0.9800850030358227\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultiArmedBanditAntColonyOptimization:\n",
    "    def __init__(self, n_arms, n_ants):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_ants = n_ants\n",
    "        self.arms = [SVC(probability=True), LogisticRegression(), RandomForestClassifier(), self.create_dnn_model()]\n",
    "        self.pheromone = np.ones(n_arms)\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "    def create_dnn_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def choose_arm(self):\n",
    "        probabilities = self.pheromone / np.sum(self.pheromone)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.n_arms)\n",
    "        else:\n",
    "            return np.random.choice(self.n_arms, p=probabilities)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        self.pheromone[arm] += reward\n",
    "\n",
    "# Load the extracted features and labels from the CSV file\n",
    "extracted_features_path = r\"E:\\train\\encoded_features_2017.csv\"\n",
    "df_extracted_features = pd.read_csv(extracted_features_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_extracted_features.drop(columns=['Label'])\n",
    "y = df_extracted_features['Label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Multi-Armed Bandit with Ant Colony Optimization\n",
    "n_arms = 4  # Number of classifiers\n",
    "n_ants = 10  # Number of ants\n",
    "bandit = MultiArmedBanditAntColonyOptimization(n_arms, n_ants)\n",
    "\n",
    "# Train the Multi-Armed Bandit\n",
    "num_iterations = 10\n",
    "for _ in range(num_iterations):\n",
    "    for _ in range(n_ants):\n",
    "        arm = bandit.choose_arm()\n",
    "        classifier = bandit.arms[arm]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        if classifier.__class__.__name__ != 'Sequential':\n",
    "            y_pred = classifier.predict(X_train)\n",
    "            reward = accuracy_score(y_train, y_pred)\n",
    "        else:\n",
    "            _, accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
    "            reward = accuracy\n",
    "        bandit.update(arm, reward)\n",
    "\n",
    "# Choose the best classifier\n",
    "best_arm = np.argmax(bandit.pheromone)\n",
    "best_classifier = bandit.arms[best_arm]\n",
    "\n",
    "# Evaluate the best classifier on the test set\n",
    "if best_classifier.__class__.__name__ != 'Sequential':\n",
    "    y_pred = best_classifier.predict(X_test)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "else:\n",
    "    _, accuracy = best_classifier.evaluate(X_test, y_test, verbose=0)\n",
    "    y_pred = (best_classifier.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Compute detection rate (equivalent to recall)\n",
    "detection_rate = recall\n",
    "\n",
    "# Print precision, recall, detection rate, F1 score, and AUC score\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Detection Rate:\", detection_rate)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
